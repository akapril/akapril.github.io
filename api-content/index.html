{"posts":[{"title":"Wails实现读取本地文件","content":"问题 通过typescript读取本地文件会出现 allow access 思路 可以使用Go文件服务器使文件可通过http的形式访问到。 解决 // app.go type App struct { ctx context.Context mux *http.ServeMux // 定义文件服务器 paths map[string]string // 存储路由地址 } // startup is called when the app starts. The context is saved // so we can call the runtime methods func (a *App) startup(ctx context.Context) { a.ctx = ctx a.mux = http.NewServeMux() a.mux.Handle(&quot;/&quot;, http.StripPrefix(&quot;/&quot;, http.FileServer(http.Dir(&quot;/&quot;)))) if err := http.ListenAndServe(&quot;:3008&quot;, a.mux); err != nil { log.Fatal(err) } } ... // ReadImage 读取文件 func (a *App) ReadImage(name string) string { p, _ := filepath.Abs(filepath.Dir(name)) var split []string var pathPre string if strings.Contains(p, &quot;:&quot;) { split = strings.Split(p, &quot;:&quot;) if &quot;&quot; == a.paths[split[0]] { if nil == a.paths { a.paths = make(map[string]string) } a.paths[split[0]] = split[0] a.mux.Handle(&quot;/&quot;+split[0]+&quot;/&quot;, http.StripPrefix(&quot;/&quot;+split[0]+&quot;/&quot;, http.FileServer(http.Dir(split[0]+&quot;:&quot;)))) } pathPre = split[0] + &quot;\\\\&quot; + split[1] + &quot;\\\\&quot; } else { splits := strings.Split(p, &quot;\\\\&quot;) split = append(split, splits[2]) var temp string for _, item := range splits[4:] { if temp == &quot;&quot; { temp = item } else { temp = temp + &quot;\\\\&quot; + item } } split = append(split, temp) if &quot;&quot; == a.paths[split[0]] { if nil == a.paths { a.paths = make(map[string]string) } a.paths[split[0]] = split[0] // TODO 设置共享目录读取 暂时只能写死 a.mux.Handle(&quot;/&quot;+split[0]+&quot;/&quot;, http.StripPrefix(&quot;/&quot;+split[0]+&quot;/&quot;, http.FileServer(http.Dir(&quot;\\\\\\\\x.x.x.x\\\\测试&quot;)))) } pathPre = split[0] + &quot;\\\\&quot; + split[1] + &quot;\\\\&quot; } log.Println(pathPre + filepath.Base(name)) return pathPre + filepath.Base(name) } 定义触发设置路由方法 // App.d.ts export function ReadImage(arg1:string):Promise&lt;string&gt;; // App.js export function ReadImage(arg1) { return window['go']['main']['App']['ReadImage'](arg1); } // 定义go方法触发 runtime.EventsEmit(app.ctx, &quot;setPhoto&quot;, strings) // 接收触发的回调 window.runtime.EventsOn(&quot;setPhoto&quot;, function (e) { e.map((item) =&gt; { ReadImage(item).then((data) =&gt; { let url = &quot;http://localhost:3008/&quot; + data console.log(url) }); }) }) ","link":"https://akapril.github.io/wails-read-local-file/"},{"title":"Wails学习记录","content":"依赖 Go 1.18+ NPM (Node 15+) 生成项目 使用 JavaScript 生成一个 Vue 项目: wails init -n myproject -t vue 如果您更愿意使用 TypeScript: wails init -n myproject -t vue-ts 参考地址： https://wails.io/zh-Hans/ ","link":"https://akapril.github.io/wails-learn/"},{"title":"Go使用imagick实现图片合并拼接并保留原图属性","content":"问题 需要将两张图片拼接成一张图，并保证拼接完成的图片，保留指定图片的原有属性。水平分辨率、垂直分辨率不改变。 使用Go自带image类库，生成的图片水平、垂直分辨率被改为了96dpi。 解决 安装Go imagick 依赖 安装msys2 # 运行msys2 在msys2终端指定 pacman -Syuu pacman -S mingw-w64-x86_64-gcc pacman -S mingw-w64-x86_64-pkg-config pacman -S mingw-w64-x86_64-zlib pacman -S mingw-w64-x86_64-imagemagick 配置环境变量 # &lt;msys64&gt; 为msys2安装路径 PATH=&lt;msys64&gt;\\mingw64\\bin;%PATH% PKG_CONFIG_PATH=&lt;msys64&gt;\\mingw64\\lib\\pkgconfig MAGICK_CODER_MODULE_PATH=&lt;msys64&gt;\\mingw64\\lib\\ImageMagick-7.0.6\\modules-Q16HDRI\\coders 项目中使用 go build gopkg.in/gographics/imagick.v3/imagick 使用 // 使用imgick对底图进行拓展，然后将第二张图片和底图进行拼接。 func MergeImagick() error { imagick.Initialize() defer imagick.Terminate() var err error // 加载底图 bg := imagick.NewMagickWand() err = bg.ReadImage(&quot;resource/bg.jg&quot;) w := bg.GetImageWidth() h := bg.GetImageHeight() // 加载第二张图片 code := imagick.NewMagickWand() err = code.ReadImage(&quot;resource/qrcode.png&quot;) // 扩展底图高度 err = bg.ExtentImage(w, h+100, 0, 0) // 合成两张图片 imagick.COMPOSITE_OP_OVER code 覆盖 bg 第二张图覆盖在底图上 err = bg.CompositeImage(code, imagick.COMPOSITE_OP_OVER, true, 0, int(h)) // 生成图片 err = bg.WriteImage(&quot;resource/newpic.jpg&quot;) // 销毁 bg.Destroy() code.Destroy() imagick.Terminate() return err } 结果 使用imagick拼接后的图片保留了底图的属性，除了扩展后高度的增加。 后续 代码打包可执行文件，运行出现找不到dll情况，暂且不清楚所需要dll。改为调用magick程序。 安装ImageMagick 下载地址: https://imagemagick.org/script/download.php#windows 安装成功后进入终端执行以下命令， magick -version 返回ImageMagick版本信息则为正常。 Version: ImageMagick 7.1.0-50 Q16-HDRI x64 f032690:20221008 https://imagemagick.org Copyright: (C) 1999 ImageMagick Studio LLC License: https://imagemagick.org/script/license.php Features: Cipher DPC HDRI Modules OpenCL OpenMP(2.0) Delegates (built-in): bzlib cairo flif freetype gslib heic jng jp2 jpeg jxl lcms lqr lzma openexr pangocairo png ps raqm raw rsvg tiff webp xml zip zlib Compiler: Visual Studio 2022 (193331630) 代码 func MergeImagickInstall(url string) error { // 打开底图 bg, _ := os.Open(url) bgpic, _ := jpeg.Decode(bg) defer bg.Close() // 获取底图尺寸 bgpicBounds := bgpic.Bounds() resize := strconv.Itoa(bgpicBounds.Size().X) + `x` + strconv.Itoa(bgpicBounds.Size().Y+100) // 首先将底图拓展 extentShell := `magick ` + url + ` -background white -extent ` + resize + ` resource/output.jpg` extentShellCmd := exec.Command(&quot;cmd.exe&quot;, &quot;/c&quot;, extentShell) extentShellCmd.SysProcAttr = &amp;syscall.SysProcAttr{HideWindow: true} err := extentShellCmd.Run() if err != nil { log.Println(err) } // 然后将第二张图片的位置设置在 x 0 y 底图高度 的位置并合成 compositeShell := `magick composite -geometry +0+` + strconv.Itoa(bgpicBounds.Size().Y) + ` resource/qrcode.png resource/output.jpg resource/output.jpg` compositeShellCmd := exec.Command(&quot;cmd.exe&quot;, &quot;/c&quot;, compositeShell) compositeShellCmd.SysProcAttr = &amp;syscall.SysProcAttr{HideWindow: true} err = compositeShellCmd.Run() if err != nil { log.Println(err) } return err } 参考链接 https://pkg.go.dev/gopkg.in/gographics/imagick.v3 https://github.com/gographics/imagick https://www.imagemagick.org/MagickWand/ https://blog.csdn.net/qq_24127015/article/details/86525305 https://imagemagick.org/script/magick.php ","link":"https://akapril.github.io/golang-imagick-composite-image/"},{"title":"Linux修改ls命令的时间显示格式","content":"linux修改ls命令的时间显示格式 vim编辑 .bashrc，添加两条，然后:wq保存： alias date='date +&quot;%T %F&quot;' alias ls='ls --color=auto --time-style +&quot;%T %F&quot;' 或使用cat 追加： cat &gt;&gt; .bashrc &lt;&lt; EOF alias date='date +&quot;%T %F&quot;' alias ls='ls --color=auto --time-style +&quot;%T %F&quot;' EOF 参考文档: https://www.cnblogs.com/valiantjiang/p/5085576.html ","link":"https://akapril.github.io/linux-ls-command-date/"},{"title":"Linux日志清理","content":"Linux日志清理 用echo命令，将空字符串内容重定向到指定文件中 echo &quot;&quot; &gt; system.journal 说明：此方法只会清空一次，一段时间后还要再次手动清空很麻烦，这里可以用以下命令让journalctl自动维护空间 journalctl命令自动维护文件大小 只保留近一周的日志 journalctl --vacuum-time=1w 只保留500MB的日志 journalctl --vacuum-size=500M 参考文档: https://cloud.tencent.com/developer/article/1423873 https://www.cnblogs.com/sparkdev/p/8795141.html ","link":"https://akapril.github.io/linux-log-clean/"},{"title":"Elasticsearch异常maximum allowed to be analyzed for highlighting解决","content":"问题 根据指定字段进行模糊查询，进行查询后报错： {&quot;type&quot;:&quot;illegal_argument_exception&quot;,&quot;reason&quot;:&quot;The length of [message] field of [SY_yKc9yQj6HAx8MKMt1pQ] doc of [syslog] index has exceeded [1000000] - maximum allowed to be analyzed for highlighting. This maximum can be set by changing the [index.highlight.max_analyzed_offset] index level setting. For large texts, indexing with offsets or term vectors is recommended!”}} 原因 索引偏移量默认是100000，当前索引偏移量超过默认值。 解决 修改索引偏移量 curl -XPUT &quot;http://127.0.0.1:9200/_settings&quot; -H 'Content-Type: application/json' -d' { &quot;index&quot; : { &quot;highlight.max_analyzed_offset&quot; : 100000000 } } 参考文档： https://www.cnblogs.com/zhanchenjin/archive/2019/10/14/11672900.html ","link":"https://akapril.github.io/elasticsearch-error-1/"},{"title":"acme.sh免费https证书","content":"安装acme.sh curl https://get.acme.sh | sh 或者 wget -O - https://get.acme.sh | sh 最好使用第二个命令，原因：wget 命令用来从指定的URL下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。 添加环境变量： /etc/profile中添加alias acme.sh=~/.acme.sh/acme.sh，保存后执行source /etc/profile加载配置。 生成证书 http -d参数后为需要生成https证书的域名，--webroot参数为网站跟目录， 然后自动完成验证. acme.sh --issue -d mydomain.com -d www.mydomain.com --webroot /home/wwwroot/mydomain.com/ apache服务器 acme.sh --issue -d mydomain.com --apache nginx服务器 acme.sh --issue -d mydomain.com --nginx 无web服务器,根据域名生成 acme.sh --issue -d mydomain.com --standalone dns 无需服务器 acme.sh --issue --dns -d mydomain.com 然后, acme.sh 会生成相应的解析记录显示出来, 你只需要在你的域名管理面板中添加这条 txt 记录即可. 等待解析完成之后, 重新生成证书: acme.sh --renew -d mydomain.com dns 方式的真正强大之处在于可以使用域名解析商提供的api 自动添加 txt 记录完成验证. acme.sh 目前支持 cloudflare, dnspod, cloudxns, godaddy 以及 ovh 等数十种解析商的自动集成. 以 dnspod 为例, 你需要先登录到 dnspod 账号, 生成你的 api id 和 api key, 都是免费的. 然后: export DP_Id=&quot;1234&quot; export DP_Key=&quot;sADDsdasdgdsf&quot; acme.sh --issue --dns dns_dp -d aa.com -d www.aa.com 证书就会自动生成了. 这里给出的 api id 和 api key 会被自动记录下来, 将来你在使用dnspod api 的时候, 就不需要再次指定了. 直接生成就好了: acme.sh --issue -d mydomain2.com --dns dns_dp 更多：https://github.com/acmesh-official/acme.sh/wiki/dnsapi copy/安装证书 默认生成的证书都放在安装目录下: ~/.acme.sh/,请不要直接使用此目录下的文件, 例如: 不要直接让 nginx/apache 的配置文件使用这下面的文件. 这里面的文件都是内部使用, 而且目录结构可能会变化. 正确的使用方法是使用 --install-cert 命令,并指定目标位置, 然后证书文件会被copy到相应的位置, 例如: Apache example: acme.sh --install-cert -d mydomain.com \\ --cert-file /path/to/certfile/in/apache/cert.pem \\ --key-file /path/to/keyfile/in/apache/key.pem \\ --fullchain-file /path/to/fullchain/certfile/apache/fullchain.pem \\ --reloadcmd &quot;service apache2 force-reload&quot; Nginx example: acme.sh --install-cert -d example.com \\ --key-file /path/to/keyfile/in/nginx/key.pem \\ --fullchain-file /path/to/fullchain/nginx/cert.pem \\ --reloadcmd &quot;service nginx force-reload&quot; (一个小提醒, 这里用的是 service nginx force-reload, 不是 service nginx reload, 据测试, reload 并不会重新加载证书, 所以用的 force-reload) Nginx 的配置 ssl_certificate 使用 /etc/nginx/ssl/fullchain.cer ，而非 /etc/nginx/ssl/&lt;domain&gt;.cer ，否则 SSL Labs 的测试会报 Chain issues Incomplete 错误。 --install-cert命令可以携带很多参数, 来指定目标文件. 并且可以指定 reloadcmd, 当证书更新以后, reloadcmd会被自动调用,让服务器生效. Nginx配置 server { listen 443 ssl; server_name www.mydomain.com; ssl_certificate /path/to/keyfile/in/nginx/cert.pem; ssl_certificate_key /path/to/fullchain/nginx/key.pem; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #指定SSL服务器端支持的协议版本 ssl_ciphers HIGH:!aNULL:!MD5; #ssl_ciphers ALL：!ADH：!EXPORT56：RC4+RSA：+HIGH：+MEDIUM：+LOW：+SSLv2：+EXP; #指定加密算法 ssl_prefer_server_ciphers on; #在使用SSLv3和TLS协议时指定服务器的加密算法要优先于客户端的加密算法 } 续期证书 目前证书在 60 天以后会自动更新, 你无需任何操作. 今后有可能会缩短这个时间, 不过都是自动的, 你不用关心. 更新acme.sh 目前由于 acme 协议和 letsencrypt CA 都在频繁的更新, 因此 acme.sh 也经常更新以保持同步. 升级 acme.sh 到最新版 : acme.sh --upgrade 如果你不想手动升级, 可以开启自动升级: acme.sh --upgrade --auto-upgrade 之后, acme.sh 就会自动保持更新了. 你也可以随时关闭自动更新: acme.sh --upgrade --auto-upgrade 0 错误 如果出错, 请添加 debug log： acme.sh --issue ..... --debug 或者： acme.sh --issue ..... --debug 2 请参考： https://github.com/Neilpang/acme.sh/wiki/How-to-debug-acme.sh 更高级的用法请参看其他 **wiki **页面. https://github.com/Neilpang/acme.sh/wiki 参考文档: https://github.com/acmesh-official/acme.sh https://github.com/acmesh-official/acme.sh/wiki/说明 https://segmentfault.com/a/1190000022263697 https://github.com/acmesh-official/acme.sh/wiki/dnsapi ","link":"https://akapril.github.io/acme-sh-free-ssl/"},{"title":"Elasticsearch异常 Data too large","content":"问题 使用canal向elasticsearch同步数据时，出现： Data too large, data for [&lt;transport_request&gt;] would be [256669646/244.7mb], which is larger than the limit of [255013683/243.1mb], real usage: [256666520/244.7mb], new bytes reserved: [3126/3kb], usages [request=0/0b, fielddata=4812/4.6kb, in_flight_requests=3126/3kb, accounting=6615462/6.3mb] 原因 堆内存不够当前查询加载数据所以会报错。 解决 提高堆栈内存 修改elasticsearch的config目录下的jvm.options: ################################################################ ## IMPORTANT: JVM heap size ################################################################ ## ## You should always set the min and max JVM heap ## size to the same value. For example, to set ## the heap to 4 GB, set: ## ## -Xms4g ## -Xmx4g ## ## See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html ## for more information ## ################################################################ # Xms represents the initial size of total heap space # Xmx represents the maximum size of total heap space -Xms4g -Xmx6g 然后重启elasticsearch。 增加堆内存使用率，默认70%，修改为90%： curl -X PUT &quot;http://127.0.0.1:9200/_cluster/settings&quot; -H 'Content-Type: application/json' -d' { &quot;transient&quot; : { &quot;indices.breaker.total.limit&quot; : &quot;90%&quot; } } 参考文档: https://github.com/docker-library/elasticsearch/issues/98 https://www.cnblogs.com/zhanchenjin/archive/2019/10/14/11672900.html ","link":"https://akapril.github.io/elasticsearch-error-2/"},{"title":"Docker安装Elasticsearch集群","content":"准备 准备三个elasticsearch节点的配置，放在/etc/elasticsearch/目录下。 #elasticsearch1.yml # 集群名，三份配置相同 cluster.name: es-cluster-cen # 节点名，同一个集群的节点名字不能相同 node.name: node-1 # 该节点是否有资格竞选成为主节点 node.master: true # 该节点是否作为数据节点 node.data: true # 一台服务器能运行的节点数，根据需要调整 node.max_local_storage_nodes: 3 # 索引数据存储的位置 path.data: /usr/share/elasticsearch/data # 日志路径 path.logs: /usr/share/elasticsearch/log # 网关地址 network.host: 0.0.0.0 # 和其他节点通信的地址,如果不设置的话会自动获取 network.publish_host: x.x.x.x # 定义http传输监听的端口 http.port: 9200 # 设置节点之间通信的端口 transport.tcp.port: 9300 # 7.x新配置，写入候选主节点的设备地址，在开启服务后可以被选为主节点 discovery.seed_hosts: [&quot;x.x.x.x:9300&quot;,&quot;y.y.y.y:9301&quot;,&quot;z.z.z.z:9302&quot;] # 与上一个配置类似，这里用节点名 cluster.initial_master_nodes: [&quot;node-1&quot;,&quot;node-2&quot;,&quot;node-3&quot;] # 集群启动后，复活2个及以上的节点，这个服务才能被使用 gateway.recover_after_nodes: 2 # 允许跨域，可选 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; # elasticsearch2.yml cluster.name: es-cluster-cen node.name: node-2 node.master: true node.data: true node.max_local_storage_nodes: 3 path.data: /usr/share/elasticsearch/data path.logs: /usr/share/elasticsearch/log network.host: 0.0.0.0 network.publish_host: y.y.y.y http.port: 9201 transport.tcp.port: 9301 discovery.seed_hosts: [&quot;x.x.x.x:9300&quot;,&quot;y.y.y.y:9301&quot;,&quot;z.z.z.z:9302&quot;] cluster.initial_master_nodes: [&quot;node-1&quot;,&quot;node-2&quot;,&quot;node-3&quot;] gateway.recover_after_nodes: 2 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; #elasticsearch3.yml cluster.name: es-cluster-cen node.name: node-3 node.master: true node.data: true node.max_local_storage_nodes: 3 path.data: /usr/share/elasticsearch/data path.logs: /usr/share/elasticsearch/log network.host: 0.0.0.0 network.publish_host: z.z.z.z http.port: 9202 transport.tcp.port: 9302 discovery.seed_hosts: [&quot;x.x.x.x:9300&quot;,&quot;y.y.y.y:9301&quot;,&quot;z.z.z.z:9302&quot;] cluster.initial_master_nodes: [&quot;node-1&quot;,&quot;node-2&quot;,&quot;node-3&quot;] gateway.recover_after_nodes: 2 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 拉取镜像 docker pull elasticsearch:7.7.0 启动 docker run \\ -p 9200:9200 \\ -p 9300:9300 \\ -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; \\ -v /etc/elasticsearch/elasticsearch1.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ docker.elastic.co/elasticsearch/elasticsearch:7.7.0 docker run \\ -p 9201:9201 \\ -p 9301:9301 \\ -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; \\ -v /etc/elasticsearch/elasticsearch2.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ docker.elastic.co/elasticsearch/elasticsearch:7.7.0 docker run \\ -p 9202:9202 \\ -p 9302:9302 \\ -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; \\ -v /etc/elasticsearch/elasticsearch2.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ docker.elastic.co/elasticsearch/elasticsearch:7.7.0 启动完成后，任意访问一个节点查看集群状态: curl http://127.0.0.1:9200/_cluster/health 返回 { &quot;cluster_name&quot;:&quot;es-cluster-cen&quot;, &quot;status&quot;:&quot;green&quot;, &quot;timed_out&quot;:false, &quot;number_of_nodes&quot;:3, &quot;number_of_data_nodes&quot;:3, &quot;active_primary_shards&quot;:62, &quot;active_shards&quot;:93, &quot;relocating_shards&quot;:0, &quot;initializing_shards&quot;:0, &quot;unassigned_shards&quot;:31, &quot;delayed_unassigned_shards&quot;:0, &quot;number_of_pending_tasks&quot;:0, &quot;number_of_in_flight_fetch&quot;:0, &quot;task_max_waiting_in_queue_millis&quot;:0, &quot;active_shards_percent_as_number&quot;:75 } 返回结果为集群的基本信息。 参考文档: https://blog.andycen.com/2020/05/24/Elasticsearch%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D%E4%B8%8E%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/ ","link":"https://akapril.github.io/elasticsearch-cluster-install/"},{"title":"Cordova插件开发","content":"原因 蓝牙打印机型号：汉印A300(HM-A300-6624) App接入调用蓝牙打印机进行二维码的打印，使用普通cordova蓝牙链接库发送指令，无法打印条形码。 解决方案 安装plugman npm install -g plugman 创建插件项目 # 去掉&lt;&gt; plugman create --name &lt;插件名&gt; --plugin_id &lt;插件id(插件调用名)&gt; --plugin_version &lt;插件版本号(1.0.0)&gt; 添加需要开发的平台 # 添加android平台 plugman platform add --platform_name android 规范项目 修改生成的java代码包位置。 | .gitignore | package.json | plugin.xml | | +---src | \\---android | \\---cn | \\---akapril | \\---ble | BlePrintPlugin.java | \\---www BlePrintPlugin.js 修改完目录后需要修改plugin.xml(添加本地jar包处解释) 添加本地jar包 在根目录新建目录libs,将需要的jar包放入目录中。 修改plugin.xml配置 &lt;?xml version='1.0' encoding='utf-8'?&gt; &lt;plugin id=&quot;BlePrintPlugin&quot; version=&quot;1.0.0&quot; xmlns=&quot;http://apache.org/cordova/ns/plugins/1.0&quot; xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;&gt; &lt;name&gt;BlePrintPlugin&lt;/name&gt; &lt;js-module name=&quot;BlePrintPlugin&quot; src=&quot;www/BlePrintPlugin.js&quot;&gt; &lt;clobbers target=&quot;cordova.plugins.BlePrintPlugin&quot; /&gt; &lt;/js-module&gt; &lt;platform name=&quot;android&quot;&gt; &lt;config-file parent=&quot;/*&quot; target=&quot;res/xml/config.xml&quot;&gt; &lt;feature name=&quot;BlePrintPlugin&quot;&gt; &lt;!-- 修改java代码目录时候对应包 --&gt; &lt;param name=&quot;android-package&quot; value=&quot;cn.akapril.ble.BlePrintPlugin&quot; /&gt; &lt;/feature&gt; &lt;/config-file&gt; &lt;config-file parent=&quot;/*&quot; target=&quot;AndroidManifest.xml&quot;&gt;&lt;/config-file&gt; &lt;!-- 对应文件 --&gt; &lt;source-file src=&quot;libs/CPCL_V1.07.jar&quot; target-dir=&quot;libs&quot;/&gt; &lt;source-file src=&quot;src/android/cn/akapril/ble/BlePrintPlugin.java&quot; target-dir=&quot;src/cn/akapril/ble&quot; /&gt; &lt;/platform&gt; &lt;/plugin&gt; 生成package.json #插件目录下生成 plugman createpackagejson . name: (BlePrintPlugin) version: (1.0.0) description: git repository: (https://github.com/akapril/BlePrintPlugin.git) author: akapril license: (ISC) About to write to E:\\workspace\\BlePrintPlugin\\package.json: { &quot;name&quot;: &quot;BlePrintPlugin&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;cordova&quot;: { &quot;id&quot;: &quot;BlePrintPlugin&quot;, &quot;platforms&quot;: [ &quot;android&quot; ] }, &quot;repository&quot;: { &quot;type&quot;: &quot;git&quot;, &quot;url&quot;: &quot;git+https://github.com/akapril/BlePrintPlugin.git&quot; }, &quot;keywords&quot;: [ &quot;ecosystem:cordova&quot;, &quot;cordova-android&quot; ], &quot;author&quot;: &quot;akapril&quot;, &quot;license&quot;: &quot;ISC&quot;, &quot;bugs&quot;: { &quot;url&quot;: &quot;https://github.com/akapril/BlePrintPlugin/issues&quot; }, &quot;homepage&quot;: &quot;https://github.com/akapril/BlePrintPlugin#readme&quot; } Is this OK? (yes) yes 添加到cordova项目中 #去掉&lt;&gt; # 添加插件 cordova plugin add &lt;插件项目目录&gt; # 去除插件 cordova plugin remove &lt;插件名称&gt; # 获取github上的插件 cordova plugin add https://github.com/akapril/BlePrintPlugin.git 参考文档： https://cordova.apache.org/docs/en/6.x/guide/hybrid/plugins/index.html https://cordova.apache.org/docs/en/6.x/guide/platforms/android/plugin.html https://cordova.apache.org/docs/en/6.x/reference/cordova-cli/index.html#cordova-plugin-command ","link":"https://akapril.github.io/cordova-plugin/"},{"title":"Docker修改镜像文件存储位置","content":"修改docker文件存储位置 问题 因为服务器磁盘存储空间剩余不多，然后挂载了新的存储，需要迁移docker镜像文件。 解决方法 Docker默认的存放位置为：/var/lib/docker 以下命令可查看具体位置： docker info | grep &quot;Docker Root Dir&quot; 先将docker服务停止: service docker stop 将数据转移到新挂载的磁盘: mv /var/lib/docker /data/docker 移动时出现device or resource busy问题，原因是因为docker运行的某些容器挂载的目录没有被卸载。 使用以下命令查找为卸载的目录(/var/lib/docker为docker目录): cat /proc/mounts | grep &quot;/var/lib/docker&quot; | awk '{print $2}' 结果为： /var/lib/docker/overlay2/5d89f720aaca052486928e57fb8a86568e8991b0ca327518f4704ba61718beb9/merged /var/lib/docker/containers/73a873a188f3c7402e45805e5e47ff99346b016a8e9977bd609a4f242a499a25/mounts/shm /var/lib/docker/overlay2/a27aaef652a6d9edeaa9d8672ae0b79feef3cf58e28ac34c6f56d6d777af8c02/merged /var/lib/docker/containers/89483898e50f02171486bfa86708e530aa7bd257f717c8a336fba4a79e2e0b2c/mounts/shm /var/lib/docker/overlay2/94bc54b30dcc128d258a8ec94293071fddd053bc40ebf4692d2fbb719fb596e4/merged 然后使用以下命令卸载对应目录： umount var/lib/docker/containers/73a873a188f3c7402e45805e5e47ff99346b016a8e9977bd609a4f242a499a25/mounts/shm 为运行方便，编写为shell脚本 #!/bin/bash # 停止docker服务 service docker stop # 查询并卸载处于挂载中的目录 umount $(cat /proc/mounts | grep &quot;/var/lib/docker&quot; | awk '{print $2}') # 拷贝docker文件到指定目录 cp -rf /var/lib/docker /data # 重命名docker原文件，备份防止出错 mv /var/lib/docker /var/lib/dockerbak # 通过软连接指向原地址 ln -s /data/docker /var/lib/docker # 重启docker服务 service docker restart #可不删除，防止出现问题 #rm -rf /var/lib/dockerbak 参考地址： https://blog.51cto.com/forangela/1949947 https://blog.csdn.net/gulijiang2008/article/details/80591843 ","link":"https://akapril.github.io/docker-change-storage/"},{"title":"SSH免密登录","content":"添加hosts 在/etc/hosts文件中添加对应主机地址已经名称: 10.5.16.1 node1 10.5.16.2 node2 10.5.16.3 node3 10.5.16.4 node4 10.5.16.5 node5 10.5.16.6 node6 生成key 在node1服务器执行: ssh-keygen -t rsa 提示输入一些信息，默认即可: Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Created directory '/root/.ssh'. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: SHA256:xOkgW2P4IcB4epLE2H8UZywgtm/xoLUHaroqVJuoeXY root@sugon51601 The key's randomart image is: +---[RSA 2048]----+ |o++ ...oo | |o+++ .o+.. | |.+..O.*.+ | |+ .*.&amp;.* | | o* B.+ S | | = + . | |+. | |+.o E | |=o . | +----[SHA256]-----+ 然后使用以下命令将公钥拷贝到其他服务器: ssh-copy-id node2 提示输入node2服务器的密码: /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot; The authenticity of host 'node2 (10.5.16.2)' can't be established. ECDSA key fingerprint is SHA256:b3KWX6G6H7ANx8tNzhobL9su6YnmT55aGSpg3xlO4xY. ECDSA key fingerprint is MD5:25:03:35:34:e0:e7:70:2b:0b:65:87:71:c6:50:36:60. Are you sure you want to continue connecting (yes/no)? yes /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@node2's password: Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh 'node2'&quot; and check to make sure that only the key(s) you wanted were added 问题 如生成密钥时提示权限不足可修改/etc/ssh/ssh_config文件的配置(centos系统)： PermitRootLogin yes PubkeyAuthentication yes PasswordAuthentication yes 参考地址： https://yq.aliyun.com/articles/701548 ","link":"https://akapril.github.io/ssh-key-login/"},{"title":"Docker以及docker-compose安装","content":"基本信息 centos 7 阿里云 安装Docker 使用官方脚本自动安装 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 手动安装帮助（阿里云ecs可通过内网安装） centos7 # step 1: 安装必要的一些系统工具 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 # Step 2: 添加软件源信息 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # Step 3: 更新并安装 Docker-CE sudo yum makecache fast sudo yum -y install docker-ce # Step 4: 开启Docker服务 sudo service docker start 注意：其他注意事项在下面的注释中 # 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。 # vim /etc/yum.repos.d/docker-ce.repo # 将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1 # # 安装指定版本的Docker-CE: # Step 1: 查找Docker-CE的版本: # yum list docker-ce.x86_64 --showduplicates | sort -r # Loading mirror speeds from cached hostfile # Loaded plugins: branch, fastestmirror, langpacks # docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable # docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable # docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable # Available Packages # Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos) # sudo yum -y install docker-ce-[VERSION] # 注意：在某些版本之后，docker-ce安装出现了其他依赖包，如果安装失败的话请关注错误信息。例如 docker-ce 17.03 之后，需要先安装 docker-ce-selinux。 # yum list docker-ce-selinux- --showduplicates | sort -r # sudo yum -y install docker-ce-selinux-[VERSION] # 通过经典网络、VPC网络内网安装时，用以下命令替换Step 2中的命令 # 经典网络： # sudo yum-config-manager --add-repo http://mirrors.aliyuncs.com/docker-ce/linux/centos/docker-ce.repo # VPC网络： # sudo yum-config-manager --add-repo http://mirrors.could.aliyuncs.com/docker-ce/linux/centos/docker-ce.repo 镜像加速 新建或修改/etc/docker/daemon.json，加入： { &quot;registry-mirrors&quot;: [ &quot;https://dockerhub.azk8s.cn&quot;, &quot;https://reg-mirror.qiniu.com&quot; ] } 一定要确保格式没有问题，否则 docker 无法启动，修改完成后执行以下命令： #重新加载配置 sudo systemctl daemon-reload #启动Docker sudo systemctl restart docker 关闭 selinux 1、临时关闭（不用重启机器） setenforce 0 #设置SELinux 成为permissive模式 #setenforce 1 设置SELinux 成为enforcing模式 2、修改配置文件(重启机器) 修改/etc/selinux/config 文件 将SELINUX=enforcing改为SELINUX=disabled 重启机器即可 安装Docker-compose sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 使用github进行安装可能会下载失败，可先下载docker-compose安装文件后上传到服务进行安装。上传到服务器后移动到/usr/local/bin目录，使用chmod +x /usr/local/bin/docker-compose命令修改docker-compose为可执行权限。 参考地址： https://yq.aliyun.com/articles/110806 https://docs.docker.com/compose/install/ ","link":"https://akapril.github.io/docker-install-docker-compose-install/"},{"title":"Kubernetes安装","content":"基本信息 centos 7 阿里云 # 安装 kubelet kubeadm kubectl # 配置源 cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装 sudo yum install -y kubelet kubeadm kubectl #启动服务 systemctl enable kubelet &amp;&amp; systemctl start kubelet 使用kind安装 curl -Lo ./kind https://github.com/kubernetes-sigs/kind/releases/download/v0.7.0/kind-$(uname)-amd64 chmod +x ./kind mv ./kind /usr/local/bin/kind 参考文档： https://yq.aliyun.com/articles/626118 ","link":"https://akapril.github.io/k8s-install/"},{"title":"使用canal进行mysql数据实时同步","content":"场景 对数据库进行实时增量备份。 安装配置 准备 mysql数据库需要先开启 Binlog 写入功能，配置 binlog-format 为 ROW 模式，my.cnf 中配置如下 [mysqld] log-bin=mysql-bin # 开启 binlog binlog-format=ROW # 选择 ROW 模式 server_id=1 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复 拉取Docker镜像 使用docker启动canal-server 访问docker hub获取最新的版本 访问：https://hub.docker.com/r/canal/canal-server/tags/ 下载对应的版本 docker pull canal/canal-server:lastet 启动（单机模式） 使用canal提供的run.sh脚本: https://github.com/alibaba/canal/blob/master/docker/run.sh # 下载脚本 wget https://raw.githubusercontent.com/alibaba/canal/master/docker/run.sh # 构建一个destination name为sys_info的队列，命令中mysql的链接地址为需要备份的数据库 sh run.sh -e canal.auto.scan=false \\ -e canal.destinations=sys_info \\ -e canal.instance.master.address=***.mysql.***.rds.aliyuncs.com:3306 \\ -e canal.instance.dbUsername=**** \\ -e canal.instance.dbPassword=**** \\ -e canal.instance.connectionCharset=UTF-8 \\ -e canal.instance.tsdb.enable=true \\ -e canal.instance.gtidon=false docker模式下，单docker实例只能运行一个instance，主要为配置问题。 运行效果 successful代表canal-server启动成功。 启动canal-adapter 配置 canal-adapter下载地址：https://github.com/alibaba/canal/releases 获取对应canal-server(canal.deployer)版本的canal-adapter 最好使用稳定版本 #下载canal-adapter #${version} 为对应版本 如 1.1.4 wget https://github.com/alibaba/canal/releases/download/canal-${version}/canal.adapter-${version}.tar.gz #下载后解压到指定目录 tar -zxvf canal.adapter-${version}.tar.gz -C canal-adapter 修改配置文件 conf/application.yml为： server: port: 8081 spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 default-property-inclusion: non_null canal.conf: mode: tcp # kafka rocketMQ canalServerHost: 127.0.0.1:11111 batchSize: 500 syncBatchSize: 1000 retries: 0 timeout: canalAdapters: - instance: sys_info # canal instance Name or mq topic name groups: - groupId: g1 outerAdapters: #- name: logger - name: rdb # 指定为rdb类型同步 # 接收数据的新数据库 key: mysql1 # 指定adapter的唯一key, 与表映射配置中outerAdapterKey对应 properties: jdbc.driverClassName: com.mysql.jdbc.Driver # jdbc驱动名, 部分jdbc的jar包需要自行放致lib目录下 jdbc.url: jdbc:mysql://***.***.rds.aliyuncs.com:3306/sys_info?useUnicode=true # jdbc url jdbc.username: **** # jdbc username jdbc.password: **** # jdbc password threads: 5 # 并行执行的线程数, 默认为1 其中 outAdapter 的配置: name统一为rdb, key为对应的数据源的唯一标识需和下面的表映射文件中的outerAdapterKey对应, properties为目标库jdb的相关参数 adapter将会自动加载conf/rdb下的所有.yml结尾的表映射配置文件 适配器列表 #最简单的处理, 将受到的变更事件通过日志打印的方式进行输出, 如配置所示, 只需要定义name: logger即可 ... outerAdapters: - name: logger RDB表映射文件 修改 conf/rdb/mytest_user.yml文件: dataSourceKey: defaultDS # 源数据源的key, 对应上面配置的srcDataSources中的值 destination: sys_info # cannal的instance或者MQ的topic groupId: # 对应MQ模式下的groupId, 只会同步对应groupId的数据 outerAdapterKey: mysql1 # adapter key, 对应上面配置outAdapters中的key concurrent: true # 是否按主键hash并行同步, 并行同步的表必须保证主键不会更改及主键不能为其他同步表的外键!! dbMapping: database: sys_info # 源数据源的database/shcema table: user # 源数据源表名 targetTable: sys_info.tb_user # 目标数据源的库名.表名 targetPk: # 主键映射 id: id # 如果是复合主键可以换行映射多个 # mapAll: true # 是否整表映射, 要求源表和目标表字段名一模一样 (如果targetColumns也配置了映射,则以targetColumns配置为准) targetColumns: # 字段映射, 格式: 目标表字段: 源表字段, 如果字段名一样源表字段名可不填 id: name: role_id: 如果两个库之间表、字段都相同可直接进行镜像备份，Mysql 库间镜像schema DDL DML同步 ## Mirror schema synchronize config dataSourceKey: defaultDS destination: sys_info groupId: g1 outerAdapterKey: mysql1 concurrent: true dbMapping: mirrorDb: true database: sys_info 其中dbMapping.database的值代表源库和目标库的schema名称，即两库的schema要一模一样 启动 将目标库的jdbc jar包放入lib文件夹 (其他数据库放入对应的驱动) 启动canal-adapter启动器 bin/startup.sh 验证 修改mysql sys_info.user表的数据, 将会自动同步到新mysql数据库的sys_info.user表下面, 并会打出DML的log adapter管理REST接口 查询所有订阅同步的canal instance或MQ topic curl http://127.0.0.1:8081/destinations 数据同步开关 curl http://127.0.0.1:8081/syncSwitch/sys_info/off -X PUT 针对 sys_info这个canal instance/MQ topic 进行开关操作. off代表关闭, instance/topic下的同步将阻塞或者断开连接不再接收数据, on代表开启 注: 如果在配置文件中配置了 zookeeperHosts 项, 则会使用分布式锁来控制HA中的数据同步开关, 如果是单机模式则使用本地锁来控制开关 数据同步开关状态 curl http://127.0.0.1:8081/syncSwitch/sys_info 查看指定 canal instance/MQ topic 的数据同步开关状态 增加Prometheus监控 安装并部署对应平台的prometheus，参见这里 配置prometheus.yml，添加canal的job，示例： - job_name: 'canal' static_configs: - targets: ['localhost:11112'] //端口配置即为canal.properties中的canal.metrics.pull.port 导入模板(Canal_instances_tmpl.json)，参考这里 导入后效果： 参考地址： https://github.com/alibaba/canal/wiki/QuickStart https://github.com/alibaba/canal/wiki/Docker-QuickStart https://github.com/alibaba/canal/wiki/ClientAdapter https://github.com/alibaba/canal/wiki/Sync-RDB https://github.com/alibaba/canal/wiki/Prometheus-QuickStart ","link":"https://akapril.github.io/use-canal/"},{"title":"Prometheus、Grafana安装和配置监控Java应用","content":"Prometheus安装 使用docker安装 docker已经安装好之后，正式安装prometheus。 docker run -d -p 9090:9090 -v /etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml -v /etc/localtime:/etc/localtime prom/prometheus 如果启动成功，访问http://服务器地址:9090 node export 安装 docker run -d -p 9100:9100 quay.io/prometheus/node-exporter 安装完之后，需要修改prometheus.yml配置文件，增加要监听的job，需要指定job的名称，以及暴露的metrics的访问路径 - job_name: &quot;node&quot; # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: [&quot;localhost:9001&quot;] #使用宿主机内网ip 重启prometheus容器生效 Grafana安装 可以使用grafana展示监控视图。 docker run -d --name=grafana -p 3001:3000 -v /var/lib/grafana:/var/lib/grafana -v /etc/grafana/grafana.ini:/etc/grafana/grafana.ini -v /etc/localtime:/etc/localtime grafana/grafana 访问http://ip地址：指定的端口，grafana安装成功，第一次访问需要修改密码，初始密码是admin/admin,修改密码之后，需要按照新密码登录。 grafana配置 添加数据源 Name为数据源名，URL为prometheus地址 导入模板 填入8919导入模板 Prometheus Data Source为grafana添加的数据源 监控jvm web项目中增加依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt; &lt;version&gt;1.1.4&lt;/version&gt; &lt;/dependency&gt; 在application.yml中添加配置 management: endpoints: web: exposure: include: '*' #开启 Actuator 服务 metrics: #将该工程应用名称添加到计量器注册表的 tag 中 tags: application: ${spring.application.name} #应用名称比如：app 在工程启动主类中增加监控 JVM 性能指标注释下的内容： @SpringBootApplication public class WebsiteApplication { public static void main(String[] args) { SpringApplication.run(WebsiteApplication.class, args); } //监控 JVM 性能指标 @Bean MeterRegistryCustomizer&lt;MeterRegistry&gt; configurer(@Value(&quot;${spring.application.name}&quot;) String applicationName){ return registry -&gt; registry.config().commonTags(&quot;application&quot;, applicationName); } } 启动动服务，浏览器访问 http://127.0.0.1:8088/actuator/prometheus 就可以看到应用的 一系列不同类型 metrics 信息 Prometheus配置新增 在prometheus.yml文件新增如下配置： - job_name: 'application' scrape_interval: 5s metrics_path: '/actuator/prometheus' file_sd_configs: - files: ['/etc/prometheus/*.json'] 新建json文件app.json,内容如下： [ { &quot;targets&quot;: [ &quot;ip:port&quot; //项目访问地址 ], &quot;labels&quot;: { &quot;instance&quot;: &quot;app&quot;, //可使用应用名称 &quot;service&quot;: &quot;app-service&quot; } } //可增加多个项目的配置 ] 重启 Prometheus 服务，查看 Prometheu 界面 Target 中确认是否添加成功。 配置 Grafana JVM Dashboard 监控项 参考grafana配置中导入模板的操作，导入4701模板 效果如下： 参考地址： https://blog.csdn.net/aixiaoyang168/article/details/100866159 https://cloud.tencent.com/developer/article/1442143 https://www.jianshu.com/p/12df755f2c66 ","link":"https://akapril.github.io/prometheus-grafana/"},{"title":"Golang安装","content":"基本信息 centos 7 下载安装包 地址：https://studygolang.com/dl 下载对应最新安装包 #version为对应的版本号 plantfrom为平台 wget https://studygolang.com/dl/golang/go{version}.{plantfrom}-amd64.tar.gz 解压安装 解包放在/usr/local/目录下，会生成go文件夹。 tar zxvf go{version}.{plantfrom}-amd64.tar.gz -C /usr/local 配置Go环境变量 # 编辑profile文件 # vi /etc/profile # 在文件末尾添加如下内容 #go setting export GOROOT=/usr/local/go export GOPATH=/usr/local/gopath export PATH=$PATH:$GOROOT/bin 执行source /etc/profile指令，配置文件的环境变量立刻生效 source /etc/profile 验证生效 #查看go版本信息 go version #查看go环境变量配置 go env 配置代理 # 编辑profile文件 # vi /etc/profile # 在文件末尾添加如下内容 # 启用 Go Modules 功能 export GO111MODULE=on # 配置 GOPROXY 环境变量 export GOPROXY=https://goproxy.io 执行以下命令生效： source /etc/profile 参考地址： https://yq.aliyun.com/articles/645569 https://goproxy.io/zh/ ","link":"https://akapril.github.io/golang-install/"},{"title":"使用drone实现自动化部署安装配置以及踩坑","content":"基本信息 centos 7 阿里云 安装docker 参考docker以及docker-compose安装 安装Rancher1.x sudo docker run -d -v /var/lib/mysql:/var/lib/mysql --restart=unless-stopped -p 8236:8080 rancher/server 运行成功后访问ip:8236 进行配置,先设置系统管理&gt;访问控制 基础框架&gt;添加主机根据提示添加主机 API&gt;密钥生成账号API Keys 基础架构&gt;镜像库添加私有镜像库 安装Gitea 使用docker-compose运行。 sudo docker-compose -f gitea-docker-compose.yml up -d gitea-docker-compose.yml文件内容： version: '2' services: gitea: image: gitea/gitea:latest container_name: gitea ports: - &quot;10022:22&quot; - &quot;10080:3000&quot; volumes: - /var/lib/gitea:/data restart: always 访问ip:10080进入安装界面进行配置。 安装Drone 在Gitea新建OAuth Application,参考官方文档。 将生成的客户端ID和客户端密钥保存。 docker-compose.yml文件内容: version: '2' services: drone-server: image: drone/drone:1.2.1 container_name: drone-server networks: - dronenet # 让drone-server和drone-agent处于一个网络中，方便进行RPC通信 ports: - '8099:80' # Web管理面板的入口 PROTO=http 时使用该端口 - '8999:443' # Web管理面板的入口 PROTO=https 时使用该端口 - '9000:9000' # RPC服务端口 volumes: - /var/run/docker.sock:/var/run/docker.sock # docker.sock [1] - /var/lib/drone/:/var/lib/drone # drone数据存放路径 environment: - DRONE_AGENTS_ENABLED=false # 使用Runner #- DRONE_GITLAB_SERVER=${DRONE_GITLAB_SERVER} #- DRONE_GITLAB_CLIENT_ID=${DRONE_GITLAB_CLIENT_ID} #- DRONE_GITLAB_CLIENT_SECRET=${DRONE_GITLAB_CLIENT_SECRET} #- DRONE_GITHUB_SERVER=${DRONE_GITHUB_SERVER} # - DRONE_GITHUB_CLIENT_ID=${DRONE_GITHUB_CLIENT_ID} # - DRONE_GITHUB_CLIENT_SECRET=${DRONE_GITHUB_CLIENT_SECRET} - DRONE_GITEA_SERVER=${DRONE_GITEA_SERVER} # github的地址 - DRONE_GITEA_CLIENT_ID=${DRONE_GITEA_CLIENT_ID} # gitea获得的ClientID - DRONE_GITEA_CLIENT_SECRET=${DRONE_GITEA_CLIENT_SECRET} # gitea获得的ClientSecret - DRONE_RPC_SECRET=${DRONE_RPC_SECRET} # RPC秘钥 [2] - DRONE_SERVER_HOST=${DRONE_SERVER_HOST} # RPC域名(在一个实例上可以不用) - DRONE_SERVER_PROTO=${DRONE_SERVER_PROTO} # git webhook使用的协议(我建议http) - DRONE_OPEN=true # 开发drone - DRONE_DATABASE_DATASOURCE=/var/lib/drone/drone.sqlite # 数据库文件 - DRONE_DATABASE_DRIVER=sqlite3 # 数据库驱动，我这里选的sqlite #- DRONE_DATABASE_DRIVER=mysql - DRONE_DEBUG=true # 调试相关，部署的时候建议先打开 - DRONE_LOGS_DEBUG=true # 调试相关，部署的时候建议先打开 - DRONE_LOGS_TRACE=true # 调试相关，部署的时候建议先打开 - DRONE_USER_CREATE=username:***,admin:true # 初始管理员用户 gitea用户名 - TZ=Asia/Shanghai # 时区 restart: always drone-agent: image: drone/agent:1.2.1 container_name: drone-agent networks: - dronenet # 让drone-server和drone-agent处于一个网络中，方便进行RPC通信 depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock # docker.sock [1] environment: - DRONE_RPC_SERVER=http://drone-server # RPC服务地址 - DRONE_RPC_SECRET=${DRONE_RPC_SECRET} # RPC秘钥 - DRONE_RPC_PROTO=${DRONE_RPC_PROTO} # RPC协议(http || https) - DRONE_RUNNER_CAPACITY=2 # 最大并发执行的 pipeline 数 - DRONE_DEBUG=true # 调试相关，部署的时候建议先打开 - DRONE_LOGS_TRACE=true # 调试相关，部署的时候建议先打开 - TZ=Asia/Shanghai restart: always networks: dronenet: # 让drone-server和drone-agent处于一个网络中，方便进行RPC通信 [1] 因为插件本身也是一个容器，要在容器中(docker-server、drone-runnere)中运行容器。将docker.sock挂载到容器中，可以让容器通过docker unix socket API得到管理容器的能力。 [2] openssl rand -hex 16 这个命令随机生成秘钥 .env #DRONE_GITHUB_CLIENT_ID=**** #DRONE_GITHUB_CLIENT_SECRET=**** DRONE_GITEA_SERVER=http://git****com DRONE_GITEA_CLIENT_ID=**** DRONE_GITEA_CLIENT_SECRET=**** #DRONE_GITLAB_SERVER=http://git.****.com #DRONE_GITLAB_CLIENT_ID=**** #DRONE_GITLAB_CLIENT_SECRET=**** DRONE_RPC_SECRET=***** DRONE_SERVER_HOST=drone.****.com DRONE_SERVER_PROTO=https DRONE_RPC_SERVER=****:9000 DRONE_RPC_PROTO=http 将docker-compose.yml和.env放在同一目录，然后运行以下命令： sudo docker-compose up -d 参考地址： https://juejin.im/post/5d97489ee51d457824771d47 https://docs.drone.io/server/provider/gitea/ ","link":"https://akapril.github.io/docker-rancher-drone-gitea/"},{"title":"Nacos+Seata+Spring boot+Mybatis plus多数据源事务控制","content":"问题 使用Mybatis plus多数据源无法控制事务. 解决 使用Nacos为配置中心，Seata分布式事务管理. Nacos配置 单机模式下运行Nacos Linux/Unix/Mac Standalone means it is non-cluster Mode. * sh startup.sh -m standalone Windows cmd startup.cmd 或者双击 startup.cmd 文件 使用mysql 1.安装数据库，版本要求：5.6.5+ 2.初始化mysql数据库，数据库初始化文件：nacos-mysql.sql 3.修改conf/application.properties文件，增加支持mysql数据源配置（目前只支持mysql），添加mysql数据源的url、用户名和密码。 conf\\application.properties spring.datasource.platform=mysql db.num=1 db.url.0=jdbc:mysql://****:3306/nacos_devtest?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true db.user=**** db.password=**** Nacos项目中的配置 pom.xml &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-config-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-discovery-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt; application.yml nacos: discovery: server-addr: 127.0.0.1:8848 #根据实际情况配置 config: server-addr: 127.0.0.1:8848 Seata配置 建表 全局事务会话信息由3块内容构成，全局事务--&gt;分支事务--&gt;全局锁，对应表global_table、branch_table、lock_table， mysql建表脚本存放于module seata-server--&gt;conf--&gt;db_store.sql 修改store.mode 打开seata-server--&gt;conf--&gt;file.conf，修改store.mode=&quot;db&quot;;也可以在启动时加命令参数-m db指定。 ## transaction log store store { ## store mode: file、db mode = &quot;db&quot; #修改为db ## file store file { dir = &quot;sessionStore&quot; # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions max-branch-session-size = 16384 # globe session size , if exceeded throws exceptions max-global-session-size = 512 # file buffer size , if exceeded allocate new buffer file-write-buffer-cache-size = 16384 # when recover batch read size session.reload.read_size = 100 # async, sync flush-disk-mode = async } ## database store db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = &quot;dbcp&quot; ## mysql/oracle/h2/oceanbase etc. db-type = &quot;mysql&quot; #修改为mysql driver-class-name = &quot;com.mysql.jdbc.Driver&quot; url = &quot;jdbc:mysql://******:3306/seata&quot; #配置数据库地址 user = &quot;****&quot; #用户名 password = &quot;******&quot; #密码 min-conn = 1 max-conn = 3 global.table = &quot;global_table&quot; branch.table = &quot;branch_table&quot; lock-table = &quot;lock_table&quot; query-limit = 100 } } 提交配置到nacos 运行conf/nacos-config.sh将nacos-config.txt的内容发送到nacos中 transport.type=TCP transport.server=NIO transport.heartbeat=true transport.thread-factory.boss-thread-prefix=NettyBoss transport.thread-factory.worker-thread-prefix=NettyServerNIOWorker transport.thread-factory.server-executor-thread-prefix=NettyServerBizHandler transport.thread-factory.share-boss-worker=false transport.thread-factory.client-selector-thread-prefix=NettyClientSelector transport.thread-factory.client-selector-thread-size=1 transport.thread-factory.client-worker-thread-prefix=NettyClientWorkerThread transport.thread-factory.boss-thread-size=1 transport.thread-factory.worker-thread-size=8 transport.shutdown.wait=3 service.vgroup_mapping.my_test_tx_groyp=default #分组 service.enableDegrade=false service.disable=false service.max.commit.retry.timeout=-1 service.max.rollback.retry.timeout=-1 client.async.commit.buffer.limit=10000 client.lock.retry.internal=10 client.lock.retry.times=30 store.mode=db store.file.dir=file_store/data store.file.max-branch-session-size=16384 store.file.max-global-session-size=512 store.file.file-write-buffer-cache-size=16384 store.file.flush-disk-mode=async store.file.session.reload.read_size=100 store.db.driver-class-name=com.mysql.jdbc.Driver store.db.datasource=dbcp store.db.db-type=mysql store.db.url=jdbc:mysql://*********:3306/seata?useUnicode=true #数据库地址 store.db.user=******** #用户名 store.db.password=******** #密码 store.db.min-conn=1 store.db.max-conn=3 store.db.global.table=global_table store.db.branch.table=branch_table store.db.query-limit=100 store.db.lock-table=lock_table recovery.committing-retry-period=1000 recovery.asyn-committing-retry-period=1000 recovery.rollbacking-retry-period=1000 recovery.timeout-retry-period=1000 transaction.undo.data.validation=true transaction.undo.log.serialization=jackson transaction.undo.log.save.days=7 transaction.undo.log.delete.period=86400000 transaction.undo.log.table=undo_log transport.serialization=seata transport.compressor=none metrics.enabled=false metrics.registry-type=compact metrics.exporter-list=prometheus metrics.exporter-prometheus-port=9898 启动 源码启动: 执行Server.java的main方法 命令启动: seata-server.sh -h 127.0.0.1 -p 8091 -m db -n 1 -DSEATA_ENV=test -h: 注册到注册中心的ip -p: Server rpc 监听端口 -m: 全局事务会话信息存储模式，file、db，优先读取启动参数 -n: Server node，多个Server时，需区分各自节点，用于生成不同的transactionId范围，以免冲突 SEATA_ENV: 多环境配置参考 https://github.com/seata/seata/wiki/Multi-configuration-Isolation Seata项目中的配置 pom.xml &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring&lt;/artifactId&gt; &lt;version&gt;${seata.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;${seata.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- seata 依赖jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;${protobuf.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;${netty4.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; resource/registry.conf对应nacos的IP端口 registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;nacos&quot; nacos { serverAddr = &quot;localhost&quot; namespace = &quot;public&quot; cluster = &quot;default&quot; } } config { # file、nacos 、apollo、zk type = &quot;nacos&quot; nacos { serverAddr = &quot;localhost&quot; namespace = &quot;public&quot; cluster = &quot;default&quot; } } application.yml spring: cloud: alibaba: seata: tx-service-group: my_test_tx_group 参考地址： https://nacos.io/zh-cn/docs/deployment.html https://seata.io/zh-cn/ https://seata.io/zh-cn/docs/user/configurations.html https://github.com/seata/seata-samples/tree/master/springcloud-nacos-seata https://github.com/seata/seata-samples/tree/master/multiple-datasource-mybatis-plus http://seata.io/zh-cn/blog/seata-nacos-analysis.html http://seata.io/zh-cn/docs/user/configurations.html ","link":"https://akapril.github.io/springboot-seate-multiple-datasource-mybatis-plus/"},{"title":"Maven安装jar到本地仓库后jenkins编译项目引用不到问题","content":"问题 maven安装jar到本地仓库后jenkins编译项目报错 使用将jar安装到本地仓库的方法. 安装jar到本地仓库命令 mvn install:install-file -DgroupId=com.taobao.api -DartifactId=taobao-sdk -Dversion=1.0 -Dpackaging=jar -Dfile=taobao-sdk-java-auto_1565853390086-20190917.jar 然后在pom.xml文件中引入 &lt;dependency&gt; &lt;groupId&gt;com.taobao.api&lt;/groupId&gt; &lt;artifactId&gt;taobao-sdk&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; 安装后还是无法引用到jar包. 原因 因maven本地仓库的目录是在运行用户目录的.m2/reopsitory下,settings.xml文件中有说明. &lt;!-- localRepository | The path to the local repository maven will use to store artifacts. | | Default: ${user.home}/.m2/repository &lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt; --&gt; 执行jar包安装的命令是在root用户下运行的,安装后jar包被安装到了/root/.m2/repository目录下. jenkins是使用rpm文件进行的安装,安装后jenkins运行在自建的用户下. 所以在jenkins的用户下引用不到安装后的jar包. 解决 修改maven本地仓库的配置settings.xml 在&lt;settings&gt;标签内新增 &lt;!-- jenkins 用户的目录 --&gt; &lt;localRepository&gt;/var/lib/jenkins/.m2/repository&lt;/localRepository&gt; 再重新执行jar包安装命令后解决. ","link":"https://akapril.github.io/jenkins-maven/"},{"title":"Mysql保存日期mybatis查询后多8小时问题","content":"问题 发现查询出的日期数据与mysql数据库中的日期不符. mysql查询出的数据是 2019-10-15 13:31:10 mybatis查询出的数据是 2019-10-15 05:31:10. 原因 因mysql设置时区与 Tomcat java 使用的时区不同. 解决 在数据库链接配置设置时区. 增加serverTimezone=Asia/Shanghai jdbc:mysql://localhost:3306/db?serverTimezone=Asia/Shanghai 参考地址： https://blog.csdn.net/babybabyup/article/details/97802707 https://blog.csdn.net/saroll57/article/details/51837551 https://blog.csdn.net/a549654065/article/details/88664077 ","link":"https://akapril.github.io/mysql-timezone/"},{"title":"使用jenkins记录","content":"Jenkins 资料 jenkins官网：https://jenkins.io/zh/ jenkins下载地址：https://jenkins.io/zh/download/ 安装步骤参考：https://jenkins.io/zh/doc/book/installing/ jenkins配置Gitee(码云)持续集成 参考：https://gitee.com/help/articles/4193 ","link":"https://akapril.github.io/use-jenkins/"},{"title":"Spring boot分库分表方案","content":"问题 因业务原因需要实现查询多库操作，目前多个库中表结构相同。 同时使用mysql数据库和sqlserver数据库。 Sharding-jdbc方案 项目配置 依赖 &lt;dependency&gt; &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-core&lt;/artifactId&gt; &lt;version&gt;${shardingsphere.version}&lt;/version&gt; &lt;/dependency&gt; 配置sharding-jdbc参数 package com.jiahua.ddxdataserver.config; import com.zaxxer.hikari.HikariDataSource; import io.shardingsphere.api.config.rule.ShardingRuleConfiguration; import io.shardingsphere.api.config.rule.TableRuleConfiguration; import io.shardingsphere.api.config.strategy.NoneShardingStrategyConfiguration; import io.shardingsphere.shardingjdbc.api.ShardingDataSourceFactory; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Primary; import org.springframework.jdbc.datasource.DataSourceTransactionManager; import javax.sql.DataSource; import java.sql.SQLException; import java.util.HashMap; import java.util.Map; import java.util.Properties; import java.util.concurrent.ConcurrentHashMap; @Configuration public class DataSourceShardingConfig { /** * 需要手动配置事务管理器 */ @Bean public DataSourceTransactionManager transactionManager(@Qualifier(&quot;dataSource&quot;) DataSource dataSource) { return new DataSourceTransactionManager(dataSource); } @Bean(name = &quot;dataSource&quot;) @Primary public DataSource dataSource() throws SQLException { ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); // 设置分表策略 shardingRuleConfig.getTableRuleConfigs().add(orderTableRule()); shardingRuleConfig.setDefaultDataSourceName(&quot;ds0&quot;); shardingRuleConfig.setDefaultTableShardingStrategyConfig(new NoneShardingStrategyConfiguration()); Properties properties = new Properties(); properties.setProperty(&quot;sql.show&quot;, &quot;true&quot;); return ShardingDataSourceFactory.createDataSource(dataSourceMap(), shardingRuleConfig, new ConcurrentHashMap&lt;&gt;(16), properties); } private TableRuleConfiguration orderTableRule() { TableRuleConfiguration tableRule = new TableRuleConfiguration(); // 设置逻辑表名 tableRule.setLogicTable(&quot;top_XXX&quot;); // ds${0..1}.t_order_${0..2} 也可以写成 ds$-&gt;{0..1}.t_order_$-&gt;{0..1} tableRule.setActualDataNodes(&quot;ds${0..2}.top_order&quot;); return tableRule; } private Map&lt;String, DataSource&gt; dataSourceMap() { Map&lt;String, DataSource&gt; dataSourceMap = new HashMap&lt;&gt;(16); // 配置第一个数据源 HikariDataSource ds0 = new HikariDataSource(); ds0.setDriverClassName(&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;); ds0.setJdbcUrl(&quot;jdbc:sqlserver://192.168.xx.xx:1433; DatabaseName=XXXX1&quot;); ds0.setUsername(&quot;XXXX&quot;); ds0.setPassword(&quot;XXXX&quot;); // 配置第二个数据源 HikariDataSource ds1 = new HikariDataSource(); ds1.setDriverClassName(&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;); ds1.setJdbcUrl(&quot;jdbc:sqlserver://192.168.xx.xx:1433; DatabaseName=XXXX2&quot;); ds1.setUsername(&quot;XXXX&quot;); ds1.setPassword(&quot;XXXX&quot;); // 配置第三个数据源 HikariDataSource ds2 = new HikariDataSource(); ds2.setDriverClassName(&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;); ds2.setJdbcUrl(&quot;jdbc:sqlserver://192.168.XX.XX:1433; DatabaseName=XXXX3&quot;); ds2.setUsername(&quot;XXXX&quot;); ds2.setPassword(&quot;XXXX&quot;); dataSourceMap.put(&quot;ds0&quot;, ds0); dataSourceMap.put(&quot;ds1&quot;, ds1); dataSourceMap.put(&quot;ds2&quot;, ds2); return dataSourceMap; } } 存在问题 使用后发现，sqlserver数据库中nvarchar类型无法对应java中String类型，报错如下： org.springframework.dao.InvalidDataAccessApiUsageException: Error attempting to get column 'top_sku_properties_name' from result set. Cause: java.sql.SQLFeatureNotSupportedException: getNString ; getNString; nested exception is java.sql.SQLFeatureNotSupportedException: getNString 暂未找到解决办法，改用mycat. Mycat方案 mycat官网 http://mycat.io/ mycat配置 server.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!-- - - Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); - you may not use this file except in compliance with the License. - You may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 - - Unless required by applicable law or agreed to in writing, software - distributed under the License is distributed on an &quot;AS IS&quot; BASIS, - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the License for the specific language governing permissions and - limitations under the License. --&gt; &lt;!DOCTYPE mycat:server SYSTEM &quot;server.dtd&quot;&gt; &lt;mycat:server xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;system&gt; &lt;property name=&quot;nonePasswordLogin&quot;&gt;0&lt;/property&gt; &lt;!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户--&gt; &lt;property name=&quot;useHandshakeV10&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;useSqlStat&quot;&gt;0&lt;/property&gt; &lt;!-- 1为开启实时统计、0为关闭 --&gt; &lt;property name=&quot;useGlobleTableCheck&quot;&gt;0&lt;/property&gt; &lt;!-- 1为开启全加班一致性检测、0为关闭 --&gt; &lt;property name=&quot;sqlExecuteTimeout&quot;&gt;300&lt;/property&gt; &lt;!-- SQL 执行超时 单位:秒--&gt; &lt;property name=&quot;sequnceHandlerType&quot;&gt;2&lt;/property&gt; &lt;!--&lt;property name=&quot;sequnceHandlerPattern&quot;&gt;(?:(\\s*next\\s+value\\s+for\\s*MYCATSEQ_(\\w+))(,|\\)|\\s)*)+&lt;/property&gt;--&gt; &lt;!--必须带有MYCATSEQ_或者 mycatseq_进入序列匹配流程 注意MYCATSEQ_有空格的情况--&gt; &lt;property name=&quot;sequnceHandlerPattern&quot;&gt;(?:(\\s*next\\s+value\\s+for\\s*MYCATSEQ_(\\w+))(,|\\)|\\s)*)+&lt;/property&gt; &lt;property name=&quot;subqueryRelationshipCheck&quot;&gt;false&lt;/property&gt; &lt;!-- 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false --&gt; &lt;!-- &lt;property name=&quot;useCompression&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--1为开启mysql压缩协议--&gt; &lt;!-- &lt;property name=&quot;fakeMySQLVersion&quot;&gt;5.6.20&lt;/property&gt;--&gt; &lt;!--设置模拟的MySQL版本号--&gt; &lt;!-- &lt;property name=&quot;processorBufferChunk&quot;&gt;40960&lt;/property&gt; --&gt; &lt;!-- &lt;property name=&quot;processors&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;processorExecutor&quot;&gt;32&lt;/property&gt; --&gt; &lt;!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena | type 2 NettyBufferPool --&gt; &lt;property name=&quot;processorBufferPoolType&quot;&gt;0&lt;/property&gt; &lt;!--默认是65535 64K 用于sql解析时最大文本长度 --&gt; &lt;!--&lt;property name=&quot;maxStringLiteralLength&quot;&gt;65535&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;sequnceHandlerType&quot;&gt;0&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;backSocketNoDelay&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;frontSocketNoDelay&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;processorExecutor&quot;&gt;16&lt;/property&gt;--&gt; &lt;!-- &lt;property name=&quot;serverPort&quot;&gt;8066&lt;/property&gt; &lt;property name=&quot;managerPort&quot;&gt;9066&lt;/property&gt; &lt;property name=&quot;idleTimeout&quot;&gt;300000&lt;/property&gt; &lt;property name=&quot;bindIp&quot;&gt;0.0.0.0&lt;/property&gt; &lt;property name=&quot;dataNodeIdleCheckPeriod&quot;&gt;300000&lt;/property&gt; 5 * 60 * 1000L; //连接空闲检查 &lt;property name=&quot;frontWriteQueueSize&quot;&gt;4096&lt;/property&gt; &lt;property name=&quot;processors&quot;&gt;32&lt;/property&gt; --&gt; &lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--&gt; &lt;property name=&quot;handleDistributedTransactions&quot;&gt;0&lt;/property&gt; &lt;!-- off heap for merge/order/group/limit 1开启 0关闭 --&gt; &lt;property name=&quot;useOffHeapForMerge&quot;&gt;1&lt;/property&gt; &lt;!-- 单位为m --&gt; &lt;property name=&quot;memoryPageSize&quot;&gt;64k&lt;/property&gt; &lt;!-- 单位为k --&gt; &lt;property name=&quot;spillsFileBufferSize&quot;&gt;1k&lt;/property&gt; &lt;property name=&quot;useStreamOutput&quot;&gt;0&lt;/property&gt; &lt;!-- 单位为m --&gt; &lt;property name=&quot;systemReserveMemorySize&quot;&gt;384m&lt;/property&gt; &lt;!--是否采用zookeeper协调切换 --&gt; &lt;property name=&quot;useZKSwitch&quot;&gt;false&lt;/property&gt; &lt;!-- XA Recovery Log日志路径 --&gt; &lt;!--&lt;property name=&quot;XARecoveryLogBaseDir&quot;&gt;./&lt;/property&gt;--&gt; &lt;!-- XA Recovery Log日志名称 --&gt; &lt;!--&lt;property name=&quot;XARecoveryLogBaseName&quot;&gt;tmlog&lt;/property&gt;--&gt; &lt;!--如果为 true的话 严格遵守隔离级别,不会在仅仅只有select语句的时候在事务中切换连接--&gt; &lt;property name=&quot;strictTxIsolation&quot;&gt;false&lt;/property&gt; &lt;property name=&quot;useZKSwitch&quot;&gt;true&lt;/property&gt; &lt;/system&gt; &lt;user name=&quot;xxxx&quot;&gt; &lt;property name=&quot;password&quot;&gt;xxxx&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;box&lt;/property&gt; &lt;/user&gt; &lt;/mycat:server&gt; schema.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt; &lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;box&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;!-- 需要查询的表 --&gt; &lt;table name=&quot;top_xxx&quot; dataNode=&quot;ds0,ds1,ds3&quot; needAddLimit=&quot;false&quot; /&gt; &lt;table name=&quot;top_xxxx&quot; dataNode=&quot;ds0,ds1,ds3&quot; needAddLimit=&quot;false&quot; /&gt; &lt;/schema&gt; &lt;!-- 数据库节点 --&gt; &lt;dataNode name=&quot;ds0&quot; dataHost=&quot;sqlserver1&quot; database=&quot;xxx1&quot; /&gt; &lt;dataNode name=&quot;ds1&quot; dataHost=&quot;sqlserver1&quot; database=&quot;xxx2&quot; /&gt; &lt;dataNode name=&quot;ds3&quot; dataHost=&quot;sqlserver1&quot; database=&quot;xxx3&quot; /&gt; &lt;!-- sqlserver数据库配置 以jdbc方式链接 --&gt; &lt;dataHost name=&quot;sqlserver1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;sqlserver&quot; dbDriver=&quot;jdbc&quot; &gt; &lt;heartbeat&gt;&lt;/heartbeat&gt; &lt;connectionInitSql&gt;&lt;/connectionInitSql&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;jdbc:sqlserver://192.168.xx.xx:1433&quot; user=&quot;xxxx&quot; password=&quot;xxxx&quot; &gt; &lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; server.xml中user标签对应schema.xml中writeHost标签的user. rule.xml 不使用规则可不配置rule.xml (待研究. 启动mycat mycat start mycat启动后默认端口为8066，用户名、密码、数据库为server.xml中user的配置. 例： &lt;user name=&quot;xxxx&quot;&gt; &lt;property name=&quot;password&quot;&gt;xxxx&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;box&lt;/property&gt; &lt;/user&gt; mycat启动后，项目中配置数据源后即可使用. 使用多数据源 同时链接mysql和mycat。 参考 多数据源配置 参考： https://github.com/xkcoding/spring-boot-demo http://www.mycat.io/document/mycat-definitive-guide.pdf ","link":"https://akapril.github.io/spring-boot-fen-ku-fen-biao-fang-an/"},{"title":"Spring boot分库分表方案","content":"问题 因业务原因需要实现查询多库操作，目前多个库中表结构相同。 同时使用mysql数据库和sqlserver数据库。 Sharding-jdbc方案 项目配置 依赖 &lt;dependency&gt; &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-core&lt;/artifactId&gt; &lt;version&gt;${shardingsphere.version}&lt;/version&gt; &lt;/dependency&gt; 配置sharding-jdbc参数 package com.jiahua.ddxdataserver.config; import com.zaxxer.hikari.HikariDataSource; import io.shardingsphere.api.config.rule.ShardingRuleConfiguration; import io.shardingsphere.api.config.rule.TableRuleConfiguration; import io.shardingsphere.api.config.strategy.NoneShardingStrategyConfiguration; import io.shardingsphere.shardingjdbc.api.ShardingDataSourceFactory; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Primary; import org.springframework.jdbc.datasource.DataSourceTransactionManager; import javax.sql.DataSource; import java.sql.SQLException; import java.util.HashMap; import java.util.Map; import java.util.Properties; import java.util.concurrent.ConcurrentHashMap; @Configuration public class DataSourceShardingConfig { /** * 需要手动配置事务管理器 */ @Bean public DataSourceTransactionManager transactionManager(@Qualifier(&quot;dataSource&quot;) DataSource dataSource) { return new DataSourceTransactionManager(dataSource); } @Bean(name = &quot;dataSource&quot;) @Primary public DataSource dataSource() throws SQLException { ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); // 设置分表策略 shardingRuleConfig.getTableRuleConfigs().add(orderTableRule()); shardingRuleConfig.setDefaultDataSourceName(&quot;ds0&quot;); shardingRuleConfig.setDefaultTableShardingStrategyConfig(new NoneShardingStrategyConfiguration()); Properties properties = new Properties(); properties.setProperty(&quot;sql.show&quot;, &quot;true&quot;); return ShardingDataSourceFactory.createDataSource(dataSourceMap(), shardingRuleConfig, new ConcurrentHashMap&lt;&gt;(16), properties); } private TableRuleConfiguration orderTableRule() { TableRuleConfiguration tableRule = new TableRuleConfiguration(); // 设置逻辑表名 tableRule.setLogicTable(&quot;top_XXX&quot;); // ds${0..1}.t_order_${0..2} 也可以写成 ds$-&gt;{0..1}.t_order_$-&gt;{0..1} tableRule.setActualDataNodes(&quot;ds${0..2}.top_order&quot;); return tableRule; } private Map&lt;String, DataSource&gt; dataSourceMap() { Map&lt;String, DataSource&gt; dataSourceMap = new HashMap&lt;&gt;(16); // 配置第一个数据源 HikariDataSource ds0 = new HikariDataSource(); ds0.setDriverClassName(&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;); ds0.setJdbcUrl(&quot;jdbc:sqlserver://192.168.xx.xx:1433; DatabaseName=XXXX1&quot;); ds0.setUsername(&quot;XXXX&quot;); ds0.setPassword(&quot;XXXX&quot;); // 配置第二个数据源 HikariDataSource ds1 = new HikariDataSource(); ds1.setDriverClassName(&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;); ds1.setJdbcUrl(&quot;jdbc:sqlserver://192.168.xx.xx:1433; DatabaseName=XXXX2&quot;); ds1.setUsername(&quot;XXXX&quot;); ds1.setPassword(&quot;XXXX&quot;); // 配置第三个数据源 HikariDataSource ds2 = new HikariDataSource(); ds2.setDriverClassName(&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;); ds2.setJdbcUrl(&quot;jdbc:sqlserver://192.168.XX.XX:1433; DatabaseName=XXXX3&quot;); ds2.setUsername(&quot;XXXX&quot;); ds2.setPassword(&quot;XXXX&quot;); dataSourceMap.put(&quot;ds0&quot;, ds0); dataSourceMap.put(&quot;ds1&quot;, ds1); dataSourceMap.put(&quot;ds2&quot;, ds2); return dataSourceMap; } } 存在问题 使用后发现，sqlserver数据库中nvarchar类型无法对应java中String类型，报错如下： org.springframework.dao.InvalidDataAccessApiUsageException: Error attempting to get column 'top_sku_properties_name' from result set. Cause: java.sql.SQLFeatureNotSupportedException: getNString ; getNString; nested exception is java.sql.SQLFeatureNotSupportedException: getNString 暂未找到解决办法，改用mycat. Mycat方案 mycat官网 http://mycat.io/ mycat配置 server.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!-- - - Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); - you may not use this file except in compliance with the License. - You may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 - - Unless required by applicable law or agreed to in writing, software - distributed under the License is distributed on an &quot;AS IS&quot; BASIS, - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the License for the specific language governing permissions and - limitations under the License. --&gt; &lt;!DOCTYPE mycat:server SYSTEM &quot;server.dtd&quot;&gt; &lt;mycat:server xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;system&gt; &lt;property name=&quot;nonePasswordLogin&quot;&gt;0&lt;/property&gt; &lt;!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户--&gt; &lt;property name=&quot;useHandshakeV10&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;useSqlStat&quot;&gt;0&lt;/property&gt; &lt;!-- 1为开启实时统计、0为关闭 --&gt; &lt;property name=&quot;useGlobleTableCheck&quot;&gt;0&lt;/property&gt; &lt;!-- 1为开启全加班一致性检测、0为关闭 --&gt; &lt;property name=&quot;sqlExecuteTimeout&quot;&gt;300&lt;/property&gt; &lt;!-- SQL 执行超时 单位:秒--&gt; &lt;property name=&quot;sequnceHandlerType&quot;&gt;2&lt;/property&gt; &lt;!--&lt;property name=&quot;sequnceHandlerPattern&quot;&gt;(?:(\\s*next\\s+value\\s+for\\s*MYCATSEQ_(\\w+))(,|\\)|\\s)*)+&lt;/property&gt;--&gt; &lt;!--必须带有MYCATSEQ_或者 mycatseq_进入序列匹配流程 注意MYCATSEQ_有空格的情况--&gt; &lt;property name=&quot;sequnceHandlerPattern&quot;&gt;(?:(\\s*next\\s+value\\s+for\\s*MYCATSEQ_(\\w+))(,|\\)|\\s)*)+&lt;/property&gt; &lt;property name=&quot;subqueryRelationshipCheck&quot;&gt;false&lt;/property&gt; &lt;!-- 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false --&gt; &lt;!-- &lt;property name=&quot;useCompression&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--1为开启mysql压缩协议--&gt; &lt;!-- &lt;property name=&quot;fakeMySQLVersion&quot;&gt;5.6.20&lt;/property&gt;--&gt; &lt;!--设置模拟的MySQL版本号--&gt; &lt;!-- &lt;property name=&quot;processorBufferChunk&quot;&gt;40960&lt;/property&gt; --&gt; &lt;!-- &lt;property name=&quot;processors&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;processorExecutor&quot;&gt;32&lt;/property&gt; --&gt; &lt;!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena | type 2 NettyBufferPool --&gt; &lt;property name=&quot;processorBufferPoolType&quot;&gt;0&lt;/property&gt; &lt;!--默认是65535 64K 用于sql解析时最大文本长度 --&gt; &lt;!--&lt;property name=&quot;maxStringLiteralLength&quot;&gt;65535&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;sequnceHandlerType&quot;&gt;0&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;backSocketNoDelay&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;frontSocketNoDelay&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;processorExecutor&quot;&gt;16&lt;/property&gt;--&gt; &lt;!-- &lt;property name=&quot;serverPort&quot;&gt;8066&lt;/property&gt; &lt;property name=&quot;managerPort&quot;&gt;9066&lt;/property&gt; &lt;property name=&quot;idleTimeout&quot;&gt;300000&lt;/property&gt; &lt;property name=&quot;bindIp&quot;&gt;0.0.0.0&lt;/property&gt; &lt;property name=&quot;dataNodeIdleCheckPeriod&quot;&gt;300000&lt;/property&gt; 5 * 60 * 1000L; //连接空闲检查 &lt;property name=&quot;frontWriteQueueSize&quot;&gt;4096&lt;/property&gt; &lt;property name=&quot;processors&quot;&gt;32&lt;/property&gt; --&gt; &lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--&gt; &lt;property name=&quot;handleDistributedTransactions&quot;&gt;0&lt;/property&gt; &lt;!-- off heap for merge/order/group/limit 1开启 0关闭 --&gt; &lt;property name=&quot;useOffHeapForMerge&quot;&gt;1&lt;/property&gt; &lt;!-- 单位为m --&gt; &lt;property name=&quot;memoryPageSize&quot;&gt;64k&lt;/property&gt; &lt;!-- 单位为k --&gt; &lt;property name=&quot;spillsFileBufferSize&quot;&gt;1k&lt;/property&gt; &lt;property name=&quot;useStreamOutput&quot;&gt;0&lt;/property&gt; &lt;!-- 单位为m --&gt; &lt;property name=&quot;systemReserveMemorySize&quot;&gt;384m&lt;/property&gt; &lt;!--是否采用zookeeper协调切换 --&gt; &lt;property name=&quot;useZKSwitch&quot;&gt;false&lt;/property&gt; &lt;!-- XA Recovery Log日志路径 --&gt; &lt;!--&lt;property name=&quot;XARecoveryLogBaseDir&quot;&gt;./&lt;/property&gt;--&gt; &lt;!-- XA Recovery Log日志名称 --&gt; &lt;!--&lt;property name=&quot;XARecoveryLogBaseName&quot;&gt;tmlog&lt;/property&gt;--&gt; &lt;!--如果为 true的话 严格遵守隔离级别,不会在仅仅只有select语句的时候在事务中切换连接--&gt; &lt;property name=&quot;strictTxIsolation&quot;&gt;false&lt;/property&gt; &lt;property name=&quot;useZKSwitch&quot;&gt;true&lt;/property&gt; &lt;/system&gt; &lt;user name=&quot;xxxx&quot;&gt; &lt;property name=&quot;password&quot;&gt;xxxx&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;box&lt;/property&gt; &lt;/user&gt; &lt;/mycat:server&gt; schema.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt; &lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;box&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;!-- 需要查询的表 --&gt; &lt;table name=&quot;top_xxx&quot; dataNode=&quot;ds0,ds1,ds3&quot; needAddLimit=&quot;false&quot; /&gt; &lt;table name=&quot;top_xxxx&quot; dataNode=&quot;ds0,ds1,ds3&quot; needAddLimit=&quot;false&quot; /&gt; &lt;/schema&gt; &lt;!-- 数据库节点 --&gt; &lt;dataNode name=&quot;ds0&quot; dataHost=&quot;sqlserver1&quot; database=&quot;xxx1&quot; /&gt; &lt;dataNode name=&quot;ds1&quot; dataHost=&quot;sqlserver1&quot; database=&quot;xxx2&quot; /&gt; &lt;dataNode name=&quot;ds3&quot; dataHost=&quot;sqlserver1&quot; database=&quot;xxx3&quot; /&gt; &lt;!-- sqlserver数据库配置 以jdbc方式链接 --&gt; &lt;dataHost name=&quot;sqlserver1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;sqlserver&quot; dbDriver=&quot;jdbc&quot; &gt; &lt;heartbeat&gt;&lt;/heartbeat&gt; &lt;connectionInitSql&gt;&lt;/connectionInitSql&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;jdbc:sqlserver://192.168.xx.xx:1433&quot; user=&quot;xxxx&quot; password=&quot;xxxx&quot; &gt; &lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; server.xml中user标签对应schema.xml中writeHost标签的user. rule.xml 不使用规则可不配置rule.xml (待研究. 启动mycat mycat start mycat启动后默认端口为8066，用户名、密码、数据库为server.xml中user的配置. 例： &lt;user name=&quot;xxxx&quot;&gt; &lt;property name=&quot;password&quot;&gt;xxxx&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;box&lt;/property&gt; &lt;/user&gt; mycat启动后，项目中配置数据源后即可使用. 使用多数据源 同时链接mysql和mycat。 参考 多数据源配置 参考： https://github.com/xkcoding/spring-boot-demo http://www.mycat.io/document/mycat-definitive-guide.pdf ","link":"https://akapril.github.io/use-mycat/"},{"title":"Spring boot使用多数据源","content":"依赖： pom.xml &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;dynamic-datasource-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${baomidou.version}&lt;/version&gt; &lt;/dependency&gt; 数据源配置： application.yml spring: datasource: dynamic: datasource: master: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://129.xx.xx.xx:3306/jiahua?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false username: xxxx password: xxxx slave: driver-class-name: com.microsoft.sqlserver.jdbc.SQLServerDriver url: jdbc:sqlserver://192.168.xx.xx:1433; DatabaseName=xxx1 username: xxxx password: xxxx slave1: driver-class-name: com.microsoft.sqlserver.jdbc.SQLServerDriver url: jdbc:sqlserver://192.168.xx.xx:1433; DatabaseName=xxx2 username: xxxx password: xxxx mp-enabled: true ServiceImpl @DS: 注解在类上或方法上来切换数据源，方法上的@DS优先级大于类上的@DS 默认走从库: @DS(value = &quot;slave&quot;)在类上，默认走从库，除非在方法在添加@DS(value = &quot;master&quot;)才走主库 @Service @DS(value = &quot;slave&quot;) public class ItemServiceImpl extends ServiceImpl&lt;ItemMapper, Item&gt; implements ItemService { /** * 类上 {@code @DS(&quot;slave&quot;)} 代表默认从库，在方法上写 {@code @DS(&quot;master&quot;)} 代表默认主库 * * @param user 用户 */ @DS(&quot;master&quot;) @Override public void addUser(User user) { baseMapper.insert(user); } } ","link":"https://akapril.github.io/use-multi-datasource/"},{"title":"更换Hexo主题","content":"原主题Next的Mist 根目录下的_config.yml文件配置 themes: next themes/next目录下_config.yml文件配置 # Schemes scheme: Mist 更为主题cactus 主题地址：https://github.com/probberechts/hexo-theme-cactus 修改根目录下的_config.yml文件配置 theme: cactus theme_config: colorscheme: white 修改themes/cactus目录下_config.yml文件配置 projects_url: http://github.com/akapril nav: home: / # About: /about search: /search/ social_links: github: http://github.com/akapril posts_overview: show_all_posts: true 配置搜索 安装hexo-generator-search插件 npm install hexo-generator-search --save 创建搜索页面 hexo new page search 创建后内容修改成 title: Search type: search --- 最后在themes/cactus目录下_config.yml文件配置 nav: search: /search/ nav下导航菜单可随意命名配置 nav: 主页: / 搜索: /search/ ","link":"https://akapril.github.io/change-themes/"},{"title":"2018久石让与新日本爱乐世界梦幻交响乐团深圳音乐会","content":"深圳之旅 济南遥墙机场安检中 出发 春茧体育馆 送给久石让的花 非官方周边 非官方周边：徽章 意外收获：面基下限大佬的意外惊喜 手册 渣像素1 渣像素2 渣像素3 渣像素4 渣像素5 返程 久石让同好群中群友拍摄 ","link":"https://akapril.github.io/joehisaishi-wdo-2018-ch/"},{"title":"使用Github Page和Hexo搭建个人博客","content":"安装环境 安装git和Node.js，git下载地址,Node.js下载地址 安装完成之后，就可进行hexo博客框架的安装 这些都在本地完成的 npm install -g hexo-cli 执行完成之后hexo就安装成功了，第一步结束，环境配置完毕就可以开始创建自己的博客了 Github上创建仓库 创建与用户名对应的仓库，仓库名为your_user_name.github.io(your_user_name.github.com的好像也可以) 博客的创建 初始化项目 #init后的名字可以随便起，不会有有什么影响 hexo init deathswaltz.github.io cd deathswaltz.github.io npm install init后面是项目的名字，这样就会生成一个deathswaltz.github.io的文件夹 基础配置 打开创建出文件夹下的_config.yml文件进行配置，可以使用sublime text，这是个非常好用的编辑器 #博客名字 title: Hexo #子标题 subtitle: #博客描述 description: #作者名字 author: deathswaltz #语言 language: zh-Hans #头像 avatar: https://avatars0.githubusercontent.com/u/10008846?v=3&amp;s=460 #主题 theme: next deploy: #使用Git发布 type: git #仓库地址 repository: https://github.com/DeathsWaltz/DeathsWaltz.github.io.git branch: master 其实到现在博客差不多已经搭建的好了 现在可以执行下列命令来在本地运行起来 hexo clean hexo g hexo s 然后再浏览器通过http://localhost:4000来进行访问 发布到Github上使用以下命令： hexo clean hexo g hexo d 或者 hexo clean hexo d -g 发布到Github上之后可以使用刚才创建的仓库名来访问，如：deathswaltz.github.io 安装主题 hexo的默认主题是landscape，个人觉得这个主题并不怎么好看，所以使用next主题。 在git bash 执行git clone https://github.com/iissnan/hexo-theme-next themes/next,这样即可进行next主题下载 下载完成后，在博客所在路径下的themes文件夹下面可以看到一个名为next的文件夹。要应用这个主题，需要我们修改站点配置文件_config.yml，注意这个_config.yml是themes/next下的不要和博客主目录下的弄混了，把之前的theme: landscape修改为theme: next。这时可以hexo g和hexo s，然后在刷新浏览器就可以看到博客是next的主题了 NexT 通过 Scheme 提供主题中的主题。 Mist 是 NexT 的第一款 Scheme。启用 Mist 仅需在 主题配置文件 中将 #scheme: Mist 前面的 # 注释去掉即可。 菜单配置在 主题配置文件 的 menu。 若站点运行在子目录中，请将链接前缀的 / 去掉。默认支持的菜单项有： menu: home: / archives: /archives #about: /about #categories: /categories tags: /tags #commonweal: /404.html 创建 “关于我” 页面 新建一个 about 页面： hexo new page &quot;about&quot; 菜单显示 about 链接，在主题的 _configy.yml 设置中将 menu 中 about 前面的注释去掉即可。 创建分类页面 添加一个 分类 页面，并在菜单中显示页面链接。 新建一个页面，命名为 categories 。命令如下：hexo new page &quot;categories&quot; 编辑刚新建的页面，将页面的类型设置为 categories ，主题将自动为这个页面显示所有分类。 title: 分类 date: 2014-12-22 12:39:04 type: &quot;categories&quot; 创建标签云页面 添加一个标签云页面，并在菜单中显示页面链接。 新建一个页面，命名为 tags 。命令如下： hexo new page &quot;tags&quot; 编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。 title: All tags date: 2014-12-22 12:39:04 type: &quot;tags&quot; 在菜单中添加链接。编辑主题的 _config.yml ，添加 tags 到 menu 中。 文章摘要 在需要显示摘要的地方添加如下代码即可： 以上是摘要 &lt;!--more-- &gt; 以下是余下全文 其他配置 多说评论系统 使用多说前需要先在 多说 创建一个站点。具体步骤如下： 登录后在首页选择 “我要安装”。 创建站点，填写站点相关信息。多说域名 这一栏填写的即是你的 duoshuo_shortname。 创建站点完成后在站点配置文件 中新增 duoshuo_shortname 字段，值设置成上一步中的值。 本人第一次写博客，用Markdown也是第一次，哪里写的不好请指教。 以上 ","link":"https://akapril.github.io/build-blog/"}]}